<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 --><title>ChatGPT Might Tell the World You’re a Criminal. Can You Sue?</title><meta name="generator" content="Jekyll v3.9.3"><meta property="og:title" content="ChatGPT Might Tell the World You’re a Criminal. Can You Sue?"><meta property="og:locale" content="en_US"><link rel="canonical" href="https://nyuengelberg.org/news/chatgpt-might-tell-the-world-youre-a-criminal-can-you-sue/"><meta property="og:url" content="https://nyuengelberg.org/news/chatgpt-might-tell-the-world-youre-a-criminal-can-you-sue/"><meta property="og:type" content="website"><meta name="twitter:card" content="summary"><meta property="twitter:title" content="ChatGPT Might Tell the World You’re a Criminal. Can You Sue?"><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebPage","headline":"ChatGPT Might Tell the World You’re a Criminal. Can You Sue?","url":"https://nyuengelberg.org/news/chatgpt-might-tell-the-world-youre-a-criminal-can-you-sue/"}</script><!-- End Jekyll SEO tag --><meta property="og:image" content="https://nyuengelberg.org/images/og-image.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="ChatGPT Might Tell the World You’re a Criminal. Can You Sue?"><meta name="twitter:description" content=""><meta name="twitter:image" content="https://nyuengelberg.org/images/og-image.png"><title>ChatGPT Might Tell the World You’re a Criminal. Can You Sue?</title><link rel="shortcut icon" href="/images/favicon.png" type="image/x-icon"><!-- <link rel="stylesheet" href="/vendor/styleguide-v2.1.css"> --><link rel="stylesheet" href="/vendor/foundation.min.css"><link rel="stylesheet" href="/assets/style.min.css"><!-- <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"> --><link href="https://fonts.googleapis.com/css?family=Material+Icons|Material+Icons+Outlined|Material+Icons+Two+Tone|Material+Icons+Round|Material+Icons+Sharp" rel="stylesheet"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=EB+Garamond:wght@400;700&family=Roboto+Condensed:wght@300;400;700&display=swap" rel="stylesheet"><!-- Google tag (gtag.js) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-CMGEW0FQPK"></script><script>window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-CMGEW0FQPK');</script><script defer="defer" data-domain="nyuengelberg" src="https://plausible.io/js/script.js"></script></head><body><a href="/news/chatgpt-might-tell-the-world-youre-a-criminal-can-you-sue/#main" class="skip-to-main-content-link">Skip to main content</a><!-- <nav class="main-nav" tabindex="-1">
  <div class="main-nav__top-row">
    <div class="top-row--right">
      <button class="material-icons close-nav">chevron_left</button>
      <a class="home-icon" href="/" aria-label="home"><span class="material-icons">home</span></a>
    </div>
    <a class="nav-top-logo top-row--left" href="https://www.law.nyu.edu/">
      <img src="/images/nyu-logo.svg" alt="New York University logo" />
    </a>
  </div>
  <a class="link" href="/">Home</a>
  <a class="link" href="/our-mission">Our Mission</a>
  <a class="link" href="/our-people">Our People</a>
  <a class="link" href="/what-we-do">What We Do</a>
  <a class="link" href="/for-students">For Students</a>
  <a class="link" href="/events">Events</a>
  <a class="link" href="/outputs">Outputs</a>
  <a class="link" href="/news">News</a>
  <a class="link" href="/projects">Projects</a>
  <a class="link" href="/getting-involved">Getting Involved</a>
  <a class="link" href="/what-were-reading">What We're Reading</a>
</nav>
 --><header class="top-bar"><button class="open-nav"><span class="menu-button__decorator material-icons">more_vert</span> <span class="menu-button__text">menu</span></button><nav class="main-nav" tabindex="-1"><div class="main-nav__top-row"><div class="top-row--right"><button class="material-icons close-nav">chevron_left</button> <a class="home-icon" href="/" aria-label="home"><span class="material-icons">home</span></a></div><a class="nav-top-logo top-row--left" href="https://www.law.nyu.edu/"><img src="/images/nyu-logo.svg" alt="New York University logo"></a></div><a class="link" href="/">Home</a> <a class="link" href="/our-mission">Our Mission</a> <a class="link" href="/our-people">Our People</a> <a class="link" href="/what-we-do">What We Do</a> <a class="link" href="/for-students">For Students</a> <a class="link" href="/events">Events</a> <a class="link" href="/outputs">Outputs</a> <a class="link" href="/news">News</a> <a class="link" href="/projects">Projects</a> <a class="link" href="/getting-involved">Getting Involved</a> <a class="link" href="/what-were-reading">What We're Reading</a></nav><div class="top-bar__logo-container"><a href="/"><img class="logo" alt="logo" src="/images/ec-icon-color.svg"></a></div></header><main id="main" class="announcement-page"><!-- Layout 2 --><div class="row expanded top-section"><div class="column large-4 medium-12 small-12"><div class="project__type">January 06, 2025</div><h1>ChatGPT Might Tell the World You’re a Criminal. Can You Sue?</h1><div class="project__authors">Engelberg Center</div><div class="bar" style="background-image: url(//images.ctfassets.net/7yhm3nqs96oa/7o7YmPdOHS3aBHgCLgSEgW/e8eda8e648f848e5f51798ed070b3312/bar-y.svg)"></div><div class="sidebar"><div class="news-image-wrapper"><img src="//images.ctfassets.net/7yhm3nqs96oa/53VZdafIvOfVm9doGlVNRG/b854a28f1b75f39d5d9c9130f24e651d/TLPc-purple-square.png" alt=""></div></div></div><div class="column large-7 large-offset-1 medium-12 small-12 no-padding markdown-content"><p><em>By Catherine Wang (‘25) and Micah Musser (‘26)</em></p><p>ChatGPT <a href="https://www.reuters.com/technology/australian-mayor-readies-worlds-first-defamation-lawsuit-over-chatgpt-content-2023-04-05/">tells a user</a> that an Australian mayor spent time in prison for bribery. A court reporter who covers cases involving abuse of minors is himself accused of <a href="https://theconversation.com/why-microsofts-copilot-ai-falsely-accused-court-reporter-of-crimes-he-covered-237685">child molestation</a>. A search engine using GPT-4 to summarize search results <a href="https://www.courtlistener.com/docket/67597344/battle-v-microsoft-corporation/">conflates</a> a professor with a similarly named convicted terrorist.</p><p>These are examples of AI “<a href="https://www.ibm.com/topics/ai-hallucinations">hallucinations</a>,” a common problem that companies deploying large language models face. Chatbots like ChatGPT are trained to predict the next word in a conversation. When confronted with a new question not present in its training data, a model is likely to make up a plausible-seeming answer. This can lead to models that <a href="https://apnews.com/article/artificial-intelligence-chatgpt-fake-case-lawyers-d6ae9fa79d0542db9e1455397aef381c">cite fake legal cases</a> or recommend <a href="https://www.techopedia.com/chatgpt-at-risk-the-latest-ai-package-hallucination-cyberattack">malicious code libraries</a>.</p><p>When made by human speakers, these types of accusations could generate liability for defamation, one of the legal doctrines that the Supreme Court has <a href="https://www.oyez.org/cases/1973/72-617">long acknowledged</a> limits Americans’ free speech rights. When human speakers make false statements about others, injured parties can usually sue the speaker if they can show that the speaker acted wrongfully and harmed them as a result. But should you be able to sue an AI company like OpenAI if its tools mix you up with someone else and call you a murderer, a child molester, or a fraudster?</p><p>This month, the Technology Law and Policy Clinic at NYU School of Law weighed in with an <a href="https://firstamendment.law.uga.edu/wp-content/uploads/2024/12/Walters-v-OpenAI-Amicus-Brief-e-filed.pdf">amicus brief</a> in <em>Walters v. OpenAI</em>, a defamation case in Georgia state court. In this litigation, a public talk show host is <a href="https://www.theverge.com/2023/6/9/23755057/openai-chatgpt-false-information-defamation-lawsuit">suing OpenAI</a> based on a fictitious legal complaint that ChatGPT produced to a third-party user, erroneously describing Walters as having been accused of fraud and embezzlement. The litigation so far has raised two pressing issues that cut straight to the core of defamation law. Should we think of outputs from generative AI tools as factual assertions? And if we <em>do</em> treat them as factual assertions, how do the traditional fault requirements of defamation law—which demand that a plaintiff show a statement was made negligently or, in some cases, with “actual malice”—apply to AI companies?</p><p>On the first question, <a href="https://www.law360.com/articles/2261443">OpenAI has argued</a> that since users are warned about the possibilities of inaccuracies, they cannot reasonably believe that ChatGPT’s responses to their questions are ever accurate factual statements. But paradoxically, OpenAI markets ChatGPT as reliable and accurate. AI programs from OpenAI and others have been <a href="https://www.denverpost.com/2023/02/07/microsoft-bakes-chatgpt-like-tech-into-search-engine-bing/">mounted on search engines</a> showing AI outputs at the top of search results, and OpenAI has added a <a href="https://www.washingtonpost.com/technology/2024/10/31/openai-chatgpt-search-ai-upgrade-google/">search engine functionality to ChatGPT</a>. An average user will expect these programs to be more reliable as they become more entrenched in how people generally look for information online.</p><p>On the second question, OpenAI has dodged <a href="https://www.law360.com/articles/2261443">by arguing</a> that you can’t <em>really</em> hold an AI company responsible for the statements made by a generative AI tool because no human can monitor AI outputs in real time. But this focus on “real-time” monitoring should be worrisome, since it implies that private citizens will have no legal remedy even where AI tools repeatedly make the same false accusations about them, and even if the AI company is perfectly aware of the problem. On the other hand, Walters <a href="https://cdn.arstechnica.net/wp-content/uploads/2023/09/Walters-v-OpenAI-Amended-Complaint-9-8-2023.pdf">has claimed</a> that ChatGPT’s statements were negligently made simply because OpenAI is aware of the general risk of AI hallucinations. If that alone were enough to show negligence, it would become essentially impossible for AI companies to ever deploy generative AI tools. As a result, crippling defamation liability could prevent innovation in the development of a new technology.</p><p>The Clinic’s brief argues that there are helpful analogies found in other bodies of law that can offer alternative, more nuanced ways to evaluate the fault of AI developers. For instance, showing that developers could have made alternative design decisions that would have reduced the risk of hallucinations without undermining the product’s functionality could be one way of showing negligence. And after AI programs are out in the world, showing that an AI company did not properly monitor its outputs could be another way of showing negligence.</p><p>Ultimately, the problem of AI hallucinations forces a difficult tradeoff between the protection of private individuals’ reputations and the social goal of fostering innovation in new and (mostly) useful technologies. There are ways to accommodate these values by analogizing to other bodies of law that govern companies’ responsibilities over their products and agents. The Clinic’s brief aims to show the dangers of courts accepting simplistic arguments that either impose blanket liability or blanket immunity on AI developers for the outputs of their tools. AI hallucinations are here to stay, and the brief proposes that analyzing this risk requires an equally innovative solution to hold AI companies accountable.</p></div></div></main><footer><div class="row expanded footer"><div class="column large-5 small-12"><img class="footer--logo" src="/images/ec-logo.svg" alt="Engelberg Center logo"><div class="footer--about"><p>The Engelberg Center on Innovation Law &amp; Policy at NYU School of Law provides a unique environment where scholars can examine the key drivers of innovation as well as the law and policy that best support innovation.</p></div></div><div class="column large-4 large-offset-1 small-12"><span class="footer--section-title">Join Our Mailing List</span><div class="form"><!-- Begin Mailchimp Signup Form --><div id="mc_embed_signup"><form action="https://nyuengelberg.us3.list-manage.com/subscribe/post?u=fd77b1cbdc6e203814ed46c7a&amp;id=0bb7830d93&amp;f_id=008d4ae2f0" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate><div id="mc_embed_signup_scroll"><div class="mc-field-group"><label class="visually-hidden" for="mce-EMAIL">Email Address <span class="asterisk">*</span></label> <input type="email" value="" placeholder="Email Address*" name="EMAIL" class="required email text-area" id="mce-EMAIL" required> <span id="mce-EMAIL-HELPERTEXT" class="helper_text"></span></div><div class="mc-field-group"><label class="visually-hidden" for="mce-FNAME">First Name</label> <input type="text" value="" placeholder="First Name" name="FNAME" class="text-area" id="mce-FNAME"> <span id="mce-FNAME-HELPERTEXT" class="helper_text"></span></div><div class="mc-field-group"><label class="visually-hidden" for="mce-LNAME">Last Name</label> <input type="text" value="" placeholder="Last Name" name="LNAME" class="text-area" id="mce-LNAME"> <span id="mce-LNAME-HELPERTEXT" class="helper_text"></span></div><div class="mc-field-group input-group"><strong>I am an NYU Law student or alumni</strong><ul><li><input type="radio" value="Yes" name="STU_ALUM" id="mce-STU_ALUM-0"> <label for="mce-STU_ALUM-0">Yes</label></li><li><input type="radio" value="No" name="STU_ALUM" id="mce-STU_ALUM-1"> <label for="mce-STU_ALUM-1">No</label></li></ul><span id="mce-STU_ALUM-HELPERTEXT" class="helper_text"></span></div><div class="mc-field-group"><label for="mce-YEAR" class="year-label">If yes, my graduation year is</label> <input type="text" value="" placeholder="Year" name="YEAR" class="text-area" id="mce-YEAR"> <span id="mce-YEAR-HELPERTEXT" class="helper_text"></span></div><div id="mce-responses" class="clear"><div class="response" id="mce-error-response" style="display:none"></div><div class="response" id="mce-success-response" style="display:none"></div></div><!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups--><div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_fd77b1cbdc6e203814ed46c7a_0bb7830d93" tabindex="-1" value=""></div><div class="clear"><input type="submit" value="Submit" name="subscribe" id="mc-embedded-subscribe" class="button"></div></div></form></div><script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></script><script type="text/javascript">(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[7]='STU_ALUM';ftypes[7]='radio';fnames[8]='YEAR';ftypes[8]='text';fnames[3]='NYCBASE';ftypes[3]='radio';fnames[4]='MMERGE4';ftypes[4]='text';fnames[5]='MMERGE5';ftypes[5]='text';}(jQuery));var $mcj = jQuery.noConflict(true);</script><!--End mc_embed_signup--></div></div><div class="column large-2 small-12 footer--nav"><a href="/">Home</a> <a href="/our-mission">Our Mission</a> <a href="/our-people">Our People</a> <a href="/what-we-do">What We Do</a> <a href="/for-students">For Students</a> <a href="/events">Events</a> <a href="/outputs">Outputs</a> <a href="/news">News</a> <a href="/projects">Projects</a> <a href="/getting-involved">Getting Involved</a> <a href="/what-were-reading">What We're Reading</a> <a href="https://www.nyu.edu/footer/accessibility.html">Accessibility</a> <a href="https://www.nyu.edu/footer/copyright-and-fair-use/digital-privacy-statement.html">Privacy Policy</a></div></div></footer><div class="copyright"><div class="row expanded"><div class="column large-10 small-12"><span class="copyright--top-text">Engelberg Center on Innovation Law & Policy</span><div class="copyright--bottom-text"><p>139 MacDougal Street Room 408, New York, NY 10012</p><p><a href="mailto:engelberg.center@nyu.edu">engelberg.center@nyu.edu</a></p><p><a href="https://bsky.app/profile/nyuengelberg.org">@nyuengelberg.org</a></p></div></div><div class="column large-2 small-12"><a href="https://www.law.nyu.edu/"><img class="footer--logo" src="/images/nyu-logo.svg" alt="New York University logo"></a></div></div></div><div id="overlay" class="js-overlay"></div><script src="https://code.jquery.com/jquery-3.4.1.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script type="text/javascript" src="/vendor/twitterFetcher_min.js"></script><script src="/assets/bundle.js"></script></body></html>